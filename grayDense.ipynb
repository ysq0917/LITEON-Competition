{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grayDense.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgmRFSdfb-qe",
        "outputId": "24138593-6b28-4f82-ad63-74ca85c41978"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BJwD_ZSDRoC",
        "outputId": "5e9925b0-bb0f-4d31-b165-21b178002eac"
      },
      "source": [
        "! cp \"/content/gdrive/My Drive/racedata/graydata/GrayA\" /content/\n",
        "! cp \"/content/gdrive/My Drive/racedata/graydata/GrayB\" /content/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: -r not specified; omitting directory '/content/gdrive/My Drive/racedata/graydata/GrayA'\n",
            "cp: -r not specified; omitting directory '/content/gdrive/My Drive/racedata/graydata/GrayB'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isCERcL6nHre",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 59
        },
        "outputId": "ae5dcde8-f6fa-4f03-c1bc-f3f3d5584bc6"
      },
      "source": [
        "from PIL import Image\n",
        "img = Image.open('/content/gdrive/MyDrive/racedata/graydata/GrayA/0/20190802023050_8SSB20N60164H1DG97Y02G6_R1248_1_SolderLight.png')\n",
        "img"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=110x42 at 0x7F7B776B9D10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNrDDJQBcHo4"
      },
      "source": [
        "# load the Keras libraries.\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D , Flatten , Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import densenet\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "from keras import regularizers\n",
        "from keras import backend as K"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRL1ItGDcLvi"
      },
      "source": [
        "img_width, img_height = 224, 224\n",
        "nb_train_samples = 12000\n",
        "nb_validation_samples = 200\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "n_classes = 8"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VX6WebTmcRR7",
        "outputId": "34b7c96b-9fe9-4693-999d-2da4b6cfb933"
      },
      "source": [
        "train_data_dir = \"/content/gdrive/MyDrive/racedata/graydata/GrayA/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    zoom_range=0.2,\n",
        "    validation_split= 0.2,\n",
        "    )\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset= \"training\"\n",
        "    )\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset= \"validation\"\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9604 images belonging to 8 classes.\n",
            "Found 2396 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qxlQINfcaaM",
        "outputId": "dea97aaf-dd89-41d2-aa47-85aeaa0bfac7"
      },
      "source": [
        "test_data_dir = \"/content/gdrive/MyDrive/racedata/graydata/GrayB/\"\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "new_test_data = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 200 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yKGqLLxch35"
      },
      "source": [
        "def build_model():\n",
        "    base_model = densenet.DenseNet121(input_shape=(img_width, img_height, 3),\n",
        "                                     weights='imagenet', #add\n",
        "                                     include_top=False,\n",
        "                                     pooling='avg')\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    predictions = Dense(n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lME-amMgcpkb",
        "outputId": "e6e5b5b9-d80d-465d-8b50-a1d1a2d26b9f"
      },
      "source": [
        "model = build_model()\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mse'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 1s 0us/step\n",
            "29097984/29084464 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUnFIGoCcsZv"
      },
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
        "callbacks_list = [early_stop, reduce_lr]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "7ARAfPr5ctVI",
        "outputId": "49450d00-6370-4fc0-c2c0-8dcf64f2bd10"
      },
      "source": [
        "model_history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size,\n",
        "    callbacks=callbacks_list)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-45866b6b3092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_history = model.fit_generator(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_validation_samples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGhU4z-jc02y"
      },
      "source": [
        "#model.save('Densenetmodel.h5')\n",
        "model.save('/content/gdrive/MyDrive/racedata/GrayDenseNetmodel.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZxAbFPqc9R5"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "dir = \"/content/gdrive/MyDrive/racedata/graydata/GrayB/\"\n",
        "label = []\n",
        "path = []\n",
        "for dirname, _,filenames in os.walk(dir):\n",
        "    for filename in filenames:\n",
        "        #print(filename)\n",
        "        if os.path.splitext(filename)[1]=='.png':\n",
        "            if dirname.split()[-1]!='GT':\n",
        "                #print(os.path.split(dirname))\n",
        "                label.append(os.path.split(dirname)[1][0])\n",
        "                path.append(os.path.join(dirname,filename))\n",
        "                print(os.path.join(dirname,filename))\n",
        "df2 = pd.DataFrame(columns = ['path','label'])\n",
        "df2['path'] = path\n",
        "df2['label'] = label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OexwMoZec-TT"
      },
      "source": [
        "df2 = df2.sample(frac = 1)\n",
        "df2 = df2.groupby(['label']).head(1000)\n",
        "df2['label'] = df2['label'].astype('category')\n",
        "df2['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REL2dzm5dGno"
      },
      "source": [
        "#以A80%訓練20%驗證 再以B測試\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "pred = model.predict(new_test_data)\n",
        "pred=np.argmax(pred,axis=1)\n",
        "pred_df=df2.copy()\n",
        "labels={}\n",
        "for l,v in new_test_data.class_indices.items():\n",
        "    print(l)\n",
        "    labels.update({v:l})\n",
        "pred_df['pred']=pred\n",
        "pred_df['pred']=pred_df['pred'].apply(lambda x: labels[x])\n",
        "    \n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "print(f\"Accuracy Score: {accuracy_score(pred_df['label'],pred_df['pred'])}\")\n",
        "sns.heatmap(confusion_matrix(pred_df['label'],pred_df['pred']), annot=True, fmt='2d')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}